# synthetic_models.py - Infrastructure des mod√®les g√©n√©ratifs pour TradingLab

import numpy as np
import pandas as pd
import yfinance as yf
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class BaseGenerativeModel(ABC):
    """
    Classe abstraite pour tous les mod√®les g√©n√©ratifs
    Interface standardis√©e pour TradingLab
    """
    
    def __init__(self, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01'):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.is_fitted = False
        
    @abstractmethod
    def fit(self):
        """Estime les param√®tres du mod√®le √† partir des donn√©es historiques"""
        pass
    
    @abstractmethod
    def simulate(self, T=1, n_steps=252, n_simulations=1000):
        """G√©n√®re des donn√©es synth√©tiques"""
        pass
    
    @abstractmethod
    def to_dataframe(self):
        """Convertit les donn√©es simul√©es au format DataFrame compatible avec Backtester"""
        pass
    
    def get_model_info(self):
        """Retourne les informations du mod√®le"""
        return {
            'name': self.__class__.__name__,
            'ticker': self.ticker,
            'fitted': self.is_fitted,
            'parameters': self.get_parameters() if hasattr(self, 'get_parameters') else {}
        }

class MonteCarloGBM(BaseGenerativeModel):
    """
    Mod√®le Geometric Brownian Motion (GBM) - Le plus simple
    """
    
    def __init__(self, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01'):
        super().__init__(ticker, start_date, end_date)
        self.model_name = "Monte Carlo GBM"
        
    def fit(self):
        """Estime Œº et œÉ √† partir des donn√©es historiques"""
        print(f"üìä Calibration du mod√®le GBM pour {self.ticker}...")
        
        # T√©l√©charger les donn√©es
        try:
            data = yf.download(self.ticker, start=self.start_date, end=self.end_date, progress=False)
            self.prices = data['Close'].dropna()
            
            if len(self.prices) < 30:
                raise ValueError(f"Donn√©es insuffisantes pour {self.ticker}")
                
            # Calculer les rendements logarithmiques
            log_returns = np.log(self.prices / self.prices.shift(1)).dropna()
            
            # Param√®tres annualis√©s
            self.mu = float(log_returns.mean() * 252)  # Drift annuel
            self.sigma = float(log_returns.std() * np.sqrt(252))  # Volatilit√© annuelle
            self.S0 = float(self.prices.iloc[-1])  # Prix initial
            
            self.is_fitted = True
            
            # print(f"‚úÖ Calibration termin√©e:")
            # print(f"   ‚Ä¢ Prix initial: ${self.S0:.2f}")
            # print(f"   ‚Ä¢ Drift annuel (Œº): {self.mu*100:.2f}%")
            # print(f"   ‚Ä¢ Volatilit√© annuelle (œÉ): {self.sigma*100:.2f}%")
            
        except Exception as e:
            # print(f"‚ùå Erreur lors de la calibration: {e}")
            raise
    
    def simulate(self, T=1, n_steps=252, n_simulations=1000):
        """G√©n√®re des trajectoires GBM"""
        if not self.is_fitted:
            self.fit()
            
        # print(f"üé≤ Simulation GBM: {n_simulations} trajectoires sur {T} an(s)")
        
        self.T = T
        self.n_steps = n_steps
        self.n_simulations = n_simulations
        self.dt = T / n_steps
        
        # Initialisation
        self.simulations = np.zeros((n_steps + 1, n_simulations))
        self.simulations[0] = self.S0
        
        # G√©n√©ration vectoris√©e pour efficacit√©
        random_shocks = np.random.standard_normal((n_steps, n_simulations))
        
        for t in range(1, n_steps + 1):
            drift = (self.mu - 0.5 * self.sigma**2) * self.dt
            diffusion = self.sigma * np.sqrt(self.dt) * random_shocks[t-1]
            self.simulations[t] = self.simulations[t-1] * np.exp(drift + diffusion)
        
        # print("‚úÖ Simulation GBM termin√©e!")
        return self
    
    def to_dataframe(self, simulation_index=0):
        """Convertit une simulation au format OHLCV compatible TradingLab"""
        if not hasattr(self, 'simulations'):
            raise ValueError("Aucune simulation disponible. Lancez d'abord simulate()")
        
        # Utiliser la premi√®re simulation par d√©faut ou une sp√©cifique
        prices = self.simulations[:, simulation_index]
        
        # Cr√©er les dates
        start_date = pd.to_datetime(self.end_date)
        dates = pd.date_range(start=start_date, periods=len(prices), freq='D')
        
        # G√©n√©rer OHLCV r√©aliste √† partir des prix
        df = pd.DataFrame(index=dates)
        
        # Prix de cl√¥ture = simulation
        df['Close'] = prices
        
        # G√©n√©rer OHLV de mani√®re coh√©rente
        daily_vol = self.sigma / np.sqrt(252)  # Volatilit√© journali√®re
        
        # Variation intra-day (plus petite que la variation inter-day)
        intraday_noise = np.random.normal(0, daily_vol * 0.3, len(prices))
        
        # Open = Close pr√©c√©dent avec petit gap
        df['Open'] = df['Close'].shift(1) * (1 + np.random.normal(0, daily_vol * 0.1, len(prices)))
        df['Open'].iloc[0] = prices[0]  # Premier Open = premier prix
        
        # High et Low bas√©s sur la volatilit√© intra-day
        high_factor = 1 + np.abs(np.random.normal(0, daily_vol * 0.5, len(prices)))
        low_factor = 1 - np.abs(np.random.normal(0, daily_vol * 0.5, len(prices)))
        
        df['High'] = np.maximum(df['Open'], df['Close']) * high_factor
        df['Low'] = np.minimum(df['Open'], df['Close']) * low_factor
        
        # Volume corr√©l√© √† la volatilit√© (plus de volume = plus de volatilit√©)
        base_volume = 1000000  # Volume de base
        vol_factor = np.abs(np.diff(np.log(prices), prepend=np.log(prices[0])))
        volume_multiplier = 1 + vol_factor * 10  # Facteur d'amplification
        df['Volume'] = (base_volume * volume_multiplier).astype(int)
        
        # Nettoyer les valeurs aberrantes
        df = df.dropna()
        
        return df
    
    def get_parameters(self):
        """Retourne les param√®tres du mod√®le"""
        if not self.is_fitted:
            return {}
        return {
            'mu': self.mu,
            'sigma': self.sigma,
            'S0': self.S0
        }

class HestonSynthetic(BaseGenerativeModel):
    """
    Mod√®le de Heston avec volatilit√© stochastique
    """
    
    def __init__(self, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01'):
        super().__init__(ticker, start_date, end_date)
        self.model_name = "Heston Stochastic Volatility"
    
    def fit(self):
        """Estime les param√®tres de Heston"""
        # print(f"üìä Calibration du mod√®le Heston pour {self.ticker}...")
        
        try:
            # T√©l√©charger les donn√©es
            data = yf.download(self.ticker, start=self.start_date, end=self.end_date, progress=False)
            self.prices = data['Close'].dropna()
            self.log_returns = np.log(self.prices / self.prices.shift(1)).dropna()
            
            # Param√®tres de base
            self.mu = float(self.log_returns.mean() * 252)
            self.vol_annual = float(self.log_returns.std() * np.sqrt(252))
            self.v0 = self.vol_annual**2
            self.S0 = float(self.prices.iloc[-1])
            
            # Estimation des param√®tres Heston
            self._estimate_heston_parameters()
            
            self.is_fitted = True
            # print("‚úÖ Calibration Heston termin√©e!")
            
        except Exception as e:
            # print(f"‚ùå Erreur calibration Heston: {e}")
            raise
    
    def _estimate_heston_parameters(self):
        """Estimation simplifi√©e des param√®tres Heston"""
        # Volatilit√© r√©alis√©e
        window_size = 21
        realized_vol = self.log_returns.rolling(window=window_size).std() * np.sqrt(252)
        realized_var = realized_vol**2
        
        # Estimation simple par r√©gression
        var_series = realized_var.dropna()
        
        if len(var_series) >= 50:
            var_lagged = var_series.shift(1).dropna()
            common_idx = var_series.index.intersection(var_lagged.index)
            
            if len(common_idx) >= 20:
                try:
                    from scipy.stats import linregress
                    var_t = var_series.loc[common_idx].values
                    var_t_minus_1 = var_lagged.loc[common_idx].values
                    delta_var = var_t - var_t_minus_1
                    
                    # Nettoyer les donn√©es
                    valid_mask = ~(np.isnan(var_t_minus_1) | np.isnan(delta_var))
                    if np.sum(valid_mask) >= 10:
                        reg = linregress(var_t_minus_1[valid_mask], delta_var[valid_mask])
                        
                        dt = 1/252
                        beta = reg.slope
                        alpha = reg.intercept
                        
                        if beta < 0:  # Param√®tres valides
                            self.kappa = max(-beta / dt, 0.1)
                            self.theta = max(-alpha / beta if beta != 0 else self.v0, 0.001)
                            
                            # Xi √† partir des r√©sidus
                            residuals = delta_var[valid_mask] - (alpha + beta * var_t_minus_1[valid_mask])
                            self.xi = max(np.sqrt(np.var(residuals) / dt), 0.01)
                        else:
                            self._set_default_heston_params()
                    else:
                        self._set_default_heston_params()
                except:
                    self._set_default_heston_params()
            else:
                self._set_default_heston_params()
        else:
            self._set_default_heston_params()
        
        # Corr√©lation prix-volatilit√©
        try:
            vol_changes = realized_vol.pct_change().dropna()
            common_idx2 = self.log_returns.index.intersection(vol_changes.index)
            
            if len(common_idx2) >= 30:
                ret_aligned = self.log_returns.loc[common_idx2].values
                vol_change_aligned = vol_changes.loc[common_idx2].values
                
                valid_mask = ~(np.isnan(ret_aligned) | np.isnan(vol_change_aligned))
                if np.sum(valid_mask) >= 20:
                    corr_matrix = np.corrcoef(ret_aligned[valid_mask], vol_change_aligned[valid_mask])
                    self.rho = float(np.clip(corr_matrix[0, 1], -0.95, 0.95))
                else:
                    self.rho = -0.7
            else:
                self.rho = -0.7
        except:
            self.rho = -0.7
        
        if np.isnan(self.rho):
            self.rho = -0.7
        
        # V√©rification condition de Feller
        if 2 * self.kappa * self.theta <= self.xi**2:
            self.kappa = (self.xi**2) / (2 * self.theta) * 1.2
    
    def _set_default_heston_params(self):
        """Param√®tres Heston par d√©faut"""
        self.kappa = 2.0
        self.theta = self.v0
        self.xi = 0.3
        self.rho = -0.7
    
    def simulate(self, T=1, n_steps=252, n_simulations=1000):
        """Simule le mod√®le de Heston"""
        if not self.is_fitted:
            self.fit()
        
        # print(f"üé≤ Simulation Heston: {n_simulations} trajectoires sur {T} an(s)")
        
        self.T = T
        self.n_steps = n_steps
        self.n_simulations = n_simulations
        self.dt = T / n_steps
        
        # Initialisation
        self.S_paths = np.zeros((n_steps + 1, n_simulations))
        self.v_paths = np.zeros((n_steps + 1, n_simulations))
        
        self.S_paths[0, :] = self.S0
        self.v_paths[0, :] = self.v0
        
        # Simulation
        for t in range(1, n_steps + 1):
            # Browniens corr√©l√©s
            Z1 = np.random.standard_normal(n_simulations)
            Z2_indep = np.random.standard_normal(n_simulations)
            Z2 = self.rho * Z1 + np.sqrt(1 - self.rho**2) * Z2_indep
            
            # √âtat pr√©c√©dent
            S_prev = self.S_paths[t-1, :]
            v_prev = np.maximum(self.v_paths[t-1, :], 1e-8)
            
            # Mise √† jour variance (CIR)
            v_drift = self.kappa * (self.theta - v_prev) * self.dt
            v_diffusion = self.xi * np.sqrt(v_prev * self.dt) * Z2
            v_new = v_prev + v_drift + v_diffusion
            self.v_paths[t, :] = np.maximum(v_new, 1e-8)
            
            # Mise √† jour prix
            drift = (self.mu - 0.5 * v_prev) * self.dt
            diffusion = np.sqrt(v_prev * self.dt) * Z1
            S_new = S_prev * np.exp(drift + diffusion)
            self.S_paths[t, :] = np.maximum(S_new, 0.01)
        
        # print("‚úÖ Simulation Heston termin√©e!")
        return self
    
    def to_dataframe(self, simulation_index=0):
        """Convertit simulation Heston au format OHLCV"""
        if not hasattr(self, 'S_paths'):
            raise ValueError("Aucune simulation disponible. Lancez d'abord simulate()")
        
        prices = self.S_paths[:, simulation_index]
        volatilities = np.sqrt(self.v_paths[:, simulation_index])
        
        # Dates
        start_date = pd.to_datetime(self.end_date)
        dates = pd.date_range(start=start_date, periods=len(prices), freq='D')
        
        df = pd.DataFrame(index=dates)
        df['Close'] = prices
        
        # OHLV bas√© sur la volatilit√© stochastique
        daily_vols = volatilities / np.sqrt(252)
        
        # Open avec gaps
        df['Open'] = df['Close'].shift(1) * (1 + np.random.normal(0, daily_vols * 0.1))
        df['Open'].iloc[0] = prices[0]
        
        # High/Low bas√©s sur la volatilit√© stochastique
        high_factor = 1 + np.abs(np.random.normal(0, daily_vols * 0.6))
        low_factor = 1 - np.abs(np.random.normal(0, daily_vols * 0.6))
        
        df['High'] = np.maximum(df['Open'], df['Close']) * high_factor
        df['Low'] = np.minimum(df['Open'], df['Close']) * low_factor
        
        # Volume corr√©l√© √† la volatilit√©
        base_volume = 1000000
        vol_factor = volatilities / np.mean(volatilities)
        df['Volume'] = (base_volume * vol_factor * (1 + np.random.uniform(0.5, 1.5, len(prices)))).astype(int)
        
        return df.dropna()
    
    def get_parameters(self):
        """Retourne les param√®tres Heston"""
        if not self.is_fitted:
            return {}
        return {
            'mu': self.mu,
            'kappa': self.kappa,
            'theta': self.theta,
            'xi': self.xi,
            'rho': self.rho,
            'v0': self.v0,
            'S0': self.S0
        }

class BatesSynthetic(BaseGenerativeModel):
    """
    Mod√®le de Bates (Heston + Sauts)
    """
    
    def __init__(self, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01'):
        super().__init__(ticker, start_date, end_date)
        self.model_name = "Bates Jump-Diffusion"
    
    def fit(self):
        """Calibre le mod√®le de Bates"""
        # print(f"üìä Calibration du mod√®le Bates pour {self.ticker}...")
        
        try:
            # Donn√©es de base
            data = yf.download(self.ticker, start=self.start_date, end=self.end_date, progress=False)
            self.prices = data['Close'].dropna()
            self.log_returns = np.log(self.prices / self.prices.shift(1)).dropna()
            
            # Param√®tres de base
            self.mu = float(self.log_returns.mean() * 252)
            self.vol_annual = float(self.log_returns.std() * np.sqrt(252))
            self.v0 = self.vol_annual**2
            self.S0 = float(self.prices.iloc[-1])
            
            # D√©tection des sauts
            self._detect_jumps()
            
            # Param√®tres Heston (comme la classe pr√©c√©dente)
            self._estimate_heston_parameters()
            
            # Param√®tres de saut
            self._estimate_jump_parameters()
            
            self.is_fitted = True
            # print("‚úÖ Calibration Bates termin√©e!")
            
        except Exception as e:
            print(f"‚ùå Erreur calibration Bates: {e}")
            raise
    
    def _detect_jumps(self):
        """D√©tecte les sauts dans les donn√©es"""
        abs_returns = np.abs(self.log_returns)
        jump_threshold = 2.5
        return_std = abs_returns.std()
        self.jump_indicator = abs_returns > jump_threshold * return_std
        
        self.n_jumps = int(self.jump_indicator.sum())
        self.jump_frequency = float(self.n_jumps / len(self.log_returns))
    
    def _estimate_heston_parameters(self):
        """Estime Heston sur donn√©es filtr√©es (sans sauts)"""
        # M√™me logique que HestonSynthetic mais sur donn√©es filtr√©es
        normal_returns = self.log_returns[~self.jump_indicator]
        
        if len(normal_returns) >= 50:
            # Estimation simplifi√©e
            self.kappa = 2.0
            self.theta = self.v0
            self.xi = 0.3
            self.rho = -0.7
        else:
            self.kappa = 2.0
            self.theta = self.v0
            self.xi = 0.3
            self.rho = -0.7
    
    def _estimate_jump_parameters(self):
        """Estime les param√®tres de saut"""
        # Fr√©quence des sauts (annualis√©e)
        self.lambda_j = max(self.n_jumps / len(self.log_returns) * 252, 0.1)
        
        # Param√®tres des sauts
        jump_returns = self.log_returns[self.jump_indicator]
        
        if len(jump_returns) > 0:
            self.mu_j = float(jump_returns.mean())
            self.sigma_j = float(jump_returns.std())
        else:
            self.mu_j = 0.0
            self.sigma_j = self.vol_annual * 1.5
        
        # Ajustement du drift
        jump_compensation = self.lambda_j * (np.exp(self.mu_j + 0.5 * self.sigma_j**2) - 1)
        self.mu_adjusted = self.mu - jump_compensation
    
    def simulate(self, T=1, n_steps=252, n_simulations=1000):
        """Simule le mod√®le de Bates"""
        if not self.is_fitted:
            self.fit()
        
        # print(f"üé≤ Simulation Bates: {n_simulations} trajectoires sur {T} an(s)")
        
        self.T = T
        self.n_steps = n_steps
        self.n_simulations = n_simulations
        self.dt = T / n_steps
        
        # Initialisation
        self.S_paths = np.zeros((n_steps + 1, n_simulations))
        self.v_paths = np.zeros((n_steps + 1, n_simulations))
        self.jump_paths = np.zeros((n_steps + 1, n_simulations))
        
        self.S_paths[0, :] = self.S0
        self.v_paths[0, :] = self.v0
        
        # Simulation
        for t in range(1, n_steps + 1):
            # Browniens corr√©l√©s
            Z1 = np.random.standard_normal(n_simulations)
            Z2_indep = np.random.standard_normal(n_simulations)
            Z2 = self.rho * Z1 + np.sqrt(1 - self.rho**2) * Z2_indep
            
            # √âtat pr√©c√©dent
            S_prev = self.S_paths[t-1, :]
            v_prev = np.maximum(self.v_paths[t-1, :], 1e-8)
            
            # Mise √† jour variance (CIR)
            v_drift = self.kappa * (self.theta - v_prev) * self.dt
            v_diffusion = self.xi * np.sqrt(v_prev * self.dt) * Z2
            v_new = v_prev + v_drift + v_diffusion
            self.v_paths[t, :] = np.maximum(v_new, 1e-8)
            
            # G√©n√©ration des sauts
            n_jumps = np.random.poisson(self.lambda_j * self.dt, n_simulations)
            jump_sizes = np.zeros(n_simulations)
            
            for i in range(n_simulations):
                if n_jumps[i] > 0:
                    jumps = np.random.normal(self.mu_j, self.sigma_j, n_jumps[i])
                    jump_sizes[i] = np.sum(jumps)
            
            self.jump_paths[t, :] = jump_sizes
            
            # Mise √† jour prix (avec sauts)
            drift = (self.mu_adjusted - 0.5 * v_prev) * self.dt
            diffusion = np.sqrt(v_prev * self.dt) * Z1
            log_return = drift + diffusion + jump_sizes
            
            self.S_paths[t, :] = S_prev * np.exp(log_return)
        
        # print("‚úÖ Simulation Bates termin√©e!")
        return self
    
    def to_dataframe(self, simulation_index=0):
        """Convertit simulation Bates au format OHLCV"""
        if not hasattr(self, 'S_paths'):
            raise ValueError("Aucune simulation disponible. Lancez d'abord simulate()")
        
        prices = self.S_paths[:, simulation_index]
        volatilities = np.sqrt(self.v_paths[:, simulation_index])
        jumps = self.jump_paths[:, simulation_index]
        
        # Dates
        start_date = pd.to_datetime(self.end_date)
        dates = pd.date_range(start=start_date, periods=len(prices), freq='D')
        
        df = pd.DataFrame(index=dates)
        df['Close'] = prices
        
        # OHLV avec impact des sauts
        daily_vols = volatilities / np.sqrt(252)
        jump_impact = np.abs(jumps)  # Impact absolu des sauts
        
        # Open avec gaps plus importants lors des sauts
        gap_factor = daily_vols * 0.1 + jump_impact * 0.5
        df['Open'] = df['Close'].shift(1) * (1 + np.random.normal(0, gap_factor))
        df['Open'].iloc[0] = prices[0]
        
        # High/Low avec volatilit√© augment√©e par les sauts
        intraday_vol = daily_vols * 0.6 + jump_impact * 0.3
        high_factor = 1 + np.abs(np.random.normal(0, intraday_vol))
        low_factor = 1 - np.abs(np.random.normal(0, intraday_vol))
        
        df['High'] = np.maximum(df['Open'], df['Close']) * high_factor
        df['Low'] = np.minimum(df['Open'], df['Close']) * low_factor
        
        # Volume augment√© lors des sauts
        base_volume = 1000000
        vol_factor = volatilities / np.mean(volatilities)
        jump_volume_factor = 1 + jump_impact * 5  # Les sauts augmentent le volume
        df['Volume'] = (base_volume * vol_factor * jump_volume_factor * 
                       (1 + np.random.uniform(0.5, 1.5, len(prices)))).astype(int)
        
        return df.dropna()
    
    def get_parameters(self):
        """Retourne les param√®tres Bates"""
        if not self.is_fitted:
            return {}
        return {
            'mu': self.mu,
            'kappa': self.kappa,
            'theta': self.theta,
            'xi': self.xi,
            'rho': self.rho,
            'lambda_j': self.lambda_j,
            'mu_j': self.mu_j,
            'sigma_j': self.sigma_j,
            'v0': self.v0,
            'S0': self.S0
        }

class SABRSynthetic(BaseGenerativeModel):
    """
    Mod√®le SABR simplifi√©
    """
    
    def __init__(self, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01'):
        super().__init__(ticker, start_date, end_date)
        self.model_name = "SABR Model"
    
    def fit(self):
        """Calibre le mod√®le SABR"""
        # print(f"üìä Calibration du mod√®le SABR pour {self.ticker}...")
        
        try:
            # Donn√©es de base
            data = yf.download(self.ticker, start=self.start_date, end=self.end_date, progress=False)
            self.prices = data['Close'].dropna()
            self.log_returns = np.log(self.prices / self.prices.shift(1)).dropna()
            
            # Param√®tres de base
            self.mu = float(self.log_returns.mean() * 252)
            self.vol_annual = float(self.log_returns.std() * np.sqrt(252))
            self.F0 = float(self.prices.iloc[-1])  # Forward (= spot)
            
            # Param√®tres SABR simplifi√©s
            self.alpha0 = self.vol_annual
            self.beta = 0.5  # √âlasticit√©
            self.rho = -0.7  # Corr√©lation
            self.nu = 0.3    # Vol of vol
            
            self.is_fitted = True
            # print("‚úÖ Calibration SABR termin√©e!")
            
        except Exception as e:
            print(f"‚ùå Erreur calibration SABR: {e}")
            raise
    
    def simulate(self, T=1, n_steps=252, n_simulations=1000):
        """Simule le mod√®le SABR"""
        if not self.is_fitted:
            self.fit()
        
        # print(f"üé≤ Simulation SABR: {n_simulations} trajectoires sur {T} an(s)")
        
        self.T = T
        self.n_steps = n_steps
        self.n_simulations = n_simulations
        dt = T / n_steps
        sqrt_dt = np.sqrt(dt)
        self.F_paths = np.zeros((n_steps + 1, n_simulations))
        self.alpha_paths = np.zeros((n_steps + 1, n_simulations))
        
        # Initialisation
        self.F_paths[0, :] = self.F0
        self.alpha_paths[0, :] = self.alpha0
        
        # G√©n√©ration des nombres al√©atoires corr√©l√©s
        Z1 = np.random.standard_normal((n_steps, n_simulations))
        Z2_indep = np.random.standard_normal((n_steps, n_simulations))
        Z2 = self.rho * Z1 + np.sqrt(1 - self.rho**2) * Z2_indep
        
        # Simulation pas √† pas
        for t in range(n_steps):
            # Mise √† jour d'alpha (log-normal)
            self.alpha_paths[t+1, :] = self.alpha_paths[t, :] * np.exp(
                -0.5 * self.nu**2 * dt + self.nu * sqrt_dt * Z2[t, :]
            )
            self.alpha_paths[t+1, :] = np.maximum(self.alpha_paths[t+1, :], 1e-8)
            
            # Mise √† jour de F selon beta
            F_current = self.F_paths[t, :]
            alpha_current = self.alpha_paths[t, :]
            
            if abs(self.beta - 0.5) < 1e-10:  # Cas beta = 0.5
                F_beta = np.sqrt(np.maximum(F_current, 1e-10))
                dF = alpha_current * F_beta * sqrt_dt * Z1[t, :]
                self.F_paths[t+1, :] = F_current + dF
            else:
                # Cas g√©n√©ral
                F_beta = np.power(np.maximum(F_current, 1e-10), self.beta)
                dF = alpha_current * F_beta * sqrt_dt * Z1[t, :]
                self.F_paths[t+1, :] = F_current + dF
            
            # Protection contre valeurs n√©gatives
            self.F_paths[t+1, :] = np.maximum(self.F_paths[t+1, :], 1e-10)
        
        # print("‚úÖ Simulation SABR termin√©e!")
        return self
    
    def to_dataframe(self, simulation_index=0):
        """Convertit simulation SABR au format OHLCV"""
        if not hasattr(self, 'F_paths'):
            raise ValueError("Aucune simulation disponible. Lancez d'abord simulate()")
        
        prices = self.F_paths[:, simulation_index]
        alphas = self.alpha_paths[:, simulation_index]
        
        # Dates
        start_date = pd.to_datetime(self.end_date)
        dates = pd.date_range(start=start_date, periods=len(prices), freq='D')
        
        df = pd.DataFrame(index=dates)
        df['Close'] = prices
        
        # OHLV bas√© sur alpha (volatilit√© locale)
        local_vols = alphas / np.sqrt(252)
        
        # Open avec gaps
        df['Open'] = df['Close'].shift(1) * (1 + np.random.normal(0, local_vols * 0.1))
        df['Open'].iloc[0] = prices[0]
        
        # High/Low bas√©s sur la volatilit√© locale
        high_factor = 1 + np.abs(np.random.normal(0, local_vols * 0.6))
        low_factor = 1 - np.abs(np.random.normal(0, local_vols * 0.6))
        
        df['High'] = np.maximum(df['Open'], df['Close']) * high_factor
        df['Low'] = np.minimum(df['Open'], df['Close']) * low_factor
        
        # Volume corr√©l√© √† alpha
        base_volume = 1000000
        vol_factor = alphas / np.mean(alphas)
        df['Volume'] = (base_volume * vol_factor * (1 + np.random.uniform(0.5, 1.5, len(prices)))).astype(int)
        
        return df.dropna()
    
    def get_parameters(self):
        """Retourne les param√®tres SABR"""
        if not self.is_fitted:
            return {}
        return {
            'alpha0': self.alpha0,
            'beta': self.beta,
            'rho': self.rho,
            'nu': self.nu,
            'F0': self.F0
        }

# ========================================================================================
# FACTORY PATTERN POUR CR√âATION DE MOD√àLES
# ========================================================================================

class ModelFactory:
    """Factory pour cr√©er et g√©rer les mod√®les synth√©tiques"""
    
    AVAILABLE_MODELS = {
        'gbm': {
            'class': MonteCarloGBM,
            'name': 'Monte Carlo GBM',
            'description': 'Geometric Brownian Motion - Mod√®le le plus simple avec volatilit√© constante',
            'complexity': 'Simple',
            'parameters': ['mu', 'sigma']
        },
        'heston': {
            'class': HestonSynthetic,
            'name': 'Heston Stochastic Volatility',
            'description': 'Mod√®le avec volatilit√© stochastique - Capture les clusters de volatilit√©',
            'complexity': 'Interm√©diaire',
            'parameters': ['mu', 'kappa', 'theta', 'xi', 'rho']
        },
        'bates': {
            'class': BatesSynthetic,
            'name': 'Bates Jump-Diffusion',
            'description': 'Heston + Sauts de Poisson - Mod√®le le plus r√©aliste pour les chocs de march√©',
            'complexity': 'Avanc√©',
            'parameters': ['mu', 'kappa', 'theta', 'xi', 'rho', 'lambda_j', 'mu_j', 'sigma_j']
        },
        'sabr': {
            'class': SABRSynthetic,
            'name': 'SABR Model',
            'description': 'Stochastic Alpha Beta Rho - Populaire pour les options et d√©riv√©s',
            'complexity': 'Avanc√©',
            'parameters': ['alpha0', 'beta', 'rho', 'nu']
        }
    }
    
    @classmethod
    def create_model(cls, model_type, ticker='AAPL', start_date='2020-01-01', end_date='2025-01-01', **kwargs):
        """
        Cr√©e une instance de mod√®le
        
        Parameters:
        -----------
        model_type : str
            Type de mod√®le ('gbm', 'heston', 'bates', 'sabr')
        ticker : str
            Symbole de l'actif
        start_date : str
            Date de d√©but pour calibration
        end_date : str
            Date de fin pour calibration
        **kwargs : dict
            Param√®tres additionnels pour le mod√®le
        """
        if model_type not in cls.AVAILABLE_MODELS:
            available = ', '.join(cls.AVAILABLE_MODELS.keys())
            raise ValueError(f"Mod√®le '{model_type}' non disponible. Mod√®les disponibles: {available}")
        
        model_class = cls.AVAILABLE_MODELS[model_type]['class']
        return model_class(ticker=ticker, start_date=start_date, end_date=end_date, **kwargs)
    
    @classmethod
    def get_model_info(cls, model_type=None):
        """Retourne les informations sur les mod√®les disponibles"""
        if model_type:
            return cls.AVAILABLE_MODELS.get(model_type, {})
        return cls.AVAILABLE_MODELS
    
    @classmethod
    def list_models(cls):
        """Liste tous les mod√®les disponibles"""
        models = []
        for key, info in cls.AVAILABLE_MODELS.items():
            models.append({
                'id': key,
                'name': info['name'],
                'description': info['description'],
                'complexity': info['complexity']
            })
        return models

# ========================================================================================
# UTILITAIRES POUR L'INT√âGRATION AVEC BACKTESTER
# ========================================================================================

class SyntheticDataManager:
    """Gestionnaire pour int√©grer les donn√©es synth√©tiques avec le Backtester"""
    
    def __init__(self):
        self.generated_data = {}
        self.models = {}
    
    def generate_data(self, model_type, symbols, start_date, end_date, 
                     T=1, n_steps=252, n_simulations=1000, **model_params):
        """
        G√©n√®re des donn√©es synth√©tiques pour une liste de symboles
        
        Parameters:
        -----------
        model_type : str
            Type de mod√®le √† utiliser
        symbols : list
            Liste des symboles √† g√©n√©rer
        start_date : str
            Date de d√©but (pour calibration)
        end_date : str
            Date de fin (pour calibration)
        T : float
            Horizon de simulation en ann√©es
        n_steps : int
            Nombre de pas de temps
        n_simulations : int
            Nombre de simulations (on utilise la premi√®re)
        **model_params : dict
            Param√®tres sp√©cifiques au mod√®le
        """
        # print(f"üîÑ G√©n√©ration de donn√©es synth√©tiques avec le mod√®le {model_type}")
        
        synthetic_data = {}
        
        for symbol in symbols:
            try:
                # print(f"üìä Traitement de {symbol}...")
                
                # Cr√©er et calibrer le mod√®le
                model = ModelFactory.create_model(
                    model_type=model_type,
                    ticker=symbol,
                    start_date=start_date,
                    end_date=end_date
                )
                
                # Appliquer les param√®tres personnalis√©s si fournis
                if model_params:
                    for param, value in model_params.items():
                        if hasattr(model, param):
                            setattr(model, param, value)
                
                # Simuler
                model.fit()
                model.simulate(T=T, n_steps=n_steps, n_simulations=n_simulations)
                
                # Convertir au format OHLCV
                df = model.to_dataframe(simulation_index=0)
                synthetic_data[symbol] = df
                
                # Stocker le mod√®le pour r√©f√©rence
                self.models[symbol] = model
                
                # print(f"‚úÖ {symbol}: {len(df)} points g√©n√©r√©s")
                
            except Exception as e:
                print(f"‚ùå Erreur pour {symbol}: {e}")
                continue
        
        if not synthetic_data:
            raise ValueError("Aucune donn√©e synth√©tique g√©n√©r√©e avec succ√®s")
        
        # Convertir au format MultiIndex attendu par Backtester
        processed_data = self._convert_to_multiindex(synthetic_data)
        
        # Stocker pour r√©f√©rence
        self.generated_data[f"{model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"] = {
            'data': processed_data,
            'metadata': {
                'model_type': model_type,
                'symbols': symbols,
                'generation_date': datetime.now(),
                'simulation_params': {
                    'T': T,
                    'n_steps': n_steps,
                    'n_simulations': n_simulations
                },
                'model_params': model_params
            }
        }
        
        return processed_data
    
    def _convert_to_multiindex(self, synthetic_data):
        """
        Convertit les donn√©es synth√©tiques au format MultiIndex (symbol, indicator)
        compatible avec le Backtester existant
        """
        # print("üîß Conversion au format MultiIndex...")
        
        # Trouver les dates communes √† tous les symboles
        common_dates = None
        for symbol, df in synthetic_data.items():
            if common_dates is None:
                common_dates = set(df.index)
            else:
                common_dates &= set(df.index)
        
        if not common_dates:
            raise ValueError("Aucune date commune entre les symboles")
        
        common_dates = sorted(common_dates)
        # print(f"üìÖ {len(common_dates)} dates communes trouv√©es")
        
        # Cr√©er la structure MultiIndex
        combined_data_frames = []
        
        for symbol, df in synthetic_data.items():
            # Filtrer pour les dates communes
            df_filtered = df.loc[df.index.isin(common_dates)].copy()
            df_filtered = df_filtered.sort_index()
            
            # Cr√©er le MultiIndex (symbol, indicator)
            new_columns = pd.MultiIndex.from_tuples(
                [(symbol, col) for col in df_filtered.columns],
                names=['symbol', 'indicator']
            )
            df_filtered.columns = new_columns
            
            combined_data_frames.append(df_filtered)
        
        # Concat√©ner tous les DataFrames
        combined_data = pd.concat(combined_data_frames, axis=1)
        
        # print(f"‚úÖ Structure MultiIndex cr√©√©e: {combined_data.shape}")
        return combined_data
    
    def get_model_summary(self, symbol):
        """Retourne un r√©sum√© du mod√®le utilis√© pour un symbole"""
        if symbol not in self.models:
            return None
        
        model = self.models[symbol]
        return {
            'model_name': model.model_name,
            'symbol': symbol,
            'fitted': model.is_fitted,
            'parameters': model.get_parameters(),
            'model_info': model.get_model_info()
        }

# ========================================================================================
# EXEMPLE D'UTILISATION
# ========================================================================================

if __name__ == "__main__":
    # print("üöÄ TEST DE L'INFRASTRUCTURE DES MOD√àLES SYNTH√âTIQUES")
    # print("=" * 60)
    
    # 1. Lister les mod√®les disponibles
    # print("\nüìã Mod√®les disponibles:")
    # for model in ModelFactory.list_models():
        # print(f"  ‚Ä¢ {model['id']}: {model['name']} ({model['complexity']})")
        # print(f"    {model['description']}")
    
    # 2. Test avec un mod√®le simple (GBM)
    # print("\nüß™ Test du mod√®le GBM...")
    gbm = ModelFactory.create_model('gbm', ticker='AAPL')
    gbm.fit()
    gbm.simulate(T=1, n_steps=252, n_simulations=100)
    df_gbm = gbm.to_dataframe()
    # print(f"‚úÖ GBM: {len(df_gbm)} lignes g√©n√©r√©es")
    # print(f"   Prix initial: ${df_gbm['Close'].iloc[0]:.2f}")
    # print(f"   Prix final: ${df_gbm['Close'].iloc[-1]:.2f}")
    
    # 3. Test avec Heston
    # print("\nüß™ Test du mod√®le Heston...")
    heston = ModelFactory.create_model('heston', ticker='AAPL')
    heston.fit()
    heston.simulate(T=1, n_steps=252, n_simulations=100)
    df_heston = heston.to_dataframe()
    # print(f"‚úÖ Heston: {len(df_heston)} lignes g√©n√©r√©es")
    
    # 4. Test du SyntheticDataManager
    # print("\nüîß Test du SyntheticDataManager...")
    manager = SyntheticDataManager()
    
    try:
        synthetic_data = manager.generate_data(
            model_type='gbm',
            symbols=['AAPL', 'MSFT'],
            start_date='2020-01-01',
            end_date='2025-01-01',
            T=0.5,  # 6 mois
            n_steps=126,  # ~6 mois de trading
            n_simulations=10
        )
        
        # print(f"‚úÖ Donn√©es synth√©tiques g√©n√©r√©es: {synthetic_data.shape}")
        # print(f"   Colonnes: {list(synthetic_data.columns)}")
        # print(f"   P√©riode: {synthetic_data.index[0]} √† {synthetic_data.index[-1]}")
        
        # Test d'acc√®s aux donn√©es (format Backtester)
        aapl_close = synthetic_data[('AAPL', 'Close')]
        # print(f"   AAPL Close: ${aapl_close.iloc[0]:.2f} ‚Üí ${aapl_close.iloc[-1]:.2f}")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
    
